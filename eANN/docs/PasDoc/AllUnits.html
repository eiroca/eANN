<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/1999/REC-html401-19991224/loose.dtd">
<html>
<head>
<meta name="GENERATOR" content="PasDoc 0.11.0">
<meta http-equiv="content-type" content="text/html; charset=iso-8859-1">
<title>All Units</title>
<link rel="StyleSheet" type="text/css" href="pasdoc.css">
</head>
<body bgcolor="#ffffff" text="#000000" link="#0000ff" vlink="#800080" alink="#FF0000">
<h1 class="allitems">All Units</h1>
<table class="unitstable wide_list">
<tr class="listheader">
<th class="itemname">Name</th>
<th class="itemdesc">Description</th>
</tr>
<tr class="list">
<td class="itemname"><a class="bold"  href="eANN.html">eANN</a></td>
<td class="itemdesc">  

<p>Artificial Neural Network Library <br> <br> This implementation of several kind of neural networks was written with the intention of providing a (hopefully) easy to use, and easy to modify, OOP source code. <br> You can also have several different sized networks running simultaneously, each functioning independently of the others, or acting as inputs to other networks. It should also be very easy to modify the source so that neurons (or even whole layers) can be created/pruned during operation of the network, thus allowing dynamic expansion/contraction. <br> History: <br> 1.00 First version <br> 1.10 Starting History's Log <br> 1.11 Adding Status Property <br> 1.12 Class reengineering (added or modified): Info, Query, SupportedOper <br> 2.00 Major class reengineering now with full Delphi support <br> 2.01 Added FindCluster, ResetTraining, ANNMsg and other minor changes <br></td>
</tr>
<tr class="list2">
<td class="itemname"><a class="bold"  href="eANNCom.html">eANNCom</a></td>
<td class="itemdesc">  

<p>Artificial Competitive Neural Network <br> <br> This is an implementation of competitive artificial neural <br> History: <br> 1.00 First version <br> 1.01 Starting History's Log <br> 1.02 Sync with new ANN 1.12 <br> 2.00 Sync with new ANN 2.01 <br> 2.01 Simplified <a class="normal"  href="eANNCom.TCompetitor.html">TCompetitor</a>, <a class="normal"  href="eANNCom.TCompetitiveNetwork.html">TCompetitiveNetwork</a> now persistent. <br></td>
</tr>
<tr class="list">
<td class="itemname"><a class="bold"  href="eANNMLP.html">eANNMLP</a></td>
<td class="itemdesc">  

<p>Artificial Multi Layer Neural Network with Backpropagation <br> <br> This is an implementation of MLP artificial neural. <br> <br> History: <br> 1.00 First version <br> 1.01 Starting History's Log <br> 1.02 Sync with new ANN 1.12 <br> 2.00 Sync with new ANN 2.01 <br> 2.01 Simplified <a class="normal"  href="eANNMLP.TLayer.html">TLayer</a>, TNeruon, <a class="normal"  href="eANNMLP.TMLPNetwork.html">TMLPNetwork</a> now persistent. <br></td>
</tr>
<tr class="list2">
<td class="itemname"><a class="bold"  href="eANNMsg.html">eANNMsg</a></td>
<td class="itemdesc">  </td>
</tr>
<tr class="list">
<td class="itemname"><a class="bold"  href="eANNPLN.html">eANNPLN</a></td>
<td class="itemdesc">  

<p>Artificial Progressive Learning Neural Network <br> <br> This is an implementation of Progressive Learning neural network <br> History: <br> 1.00 First version <br> 1.01 Starting History's Log <br> 1.02 Sync with new ANN 1.12 <br> 2.00 Sync with new ANN 2.01 <br> 2.01 Simplified TPLElem, <a class="normal"  href="eANNPLN.TPLNetwork.html">TPLNetwork</a> now persistent. <br> <br> @todo Improves sorting using heap sort</td>
</tr>
<tr class="list2">
<td class="itemname"><a class="bold"  href="eANNPRB.html">eANNPRB</a></td>
<td class="itemdesc">  

<p>Artificial Progressive Radial Neural Network <br> <br> This is an implementation of Progressive Learning Radial Basis function artificial neural network <br> <br> History: <br> 1.00 First version <br> 1.01 Starting History's Log <br> 1.02 Sync with new ANN 1.12 <br> 2.01 Sync with new ANN 2.01 <br> <br> Some definition used in this documentation <br> &quot;Activation&quot; Sum of activation (gaussian function) of all neuron <br> <br> @todo Improves matrix inversion</td>
</tr>
<tr class="list">
<td class="itemname"><a class="bold"  href="eANNRB.html">eANNRB</a></td>
<td class="itemdesc">  

<p>Artificial Radia Basis Neural Network <br> <br> This is an implementation of Radial Basis neural network <br> <br> History: <br> 1.00 First version <br> 2.01 Sync with new ANN 2.01 <br> <br> @todo Improves matrix inversion <br> Some definition used in this documentation <br> YC[n,i] the output predicted by the network <br> Y[n,i] the &quot;real&quot; output <br> E[n,i] = abs(YC[n,i]-Y[n,i]) the absolute error of a single vector elemement of a given sample <br> Er[n,i] = E[n,i] / Y[n,i] the relative error of a single vector elemement of a given sample <br> D[n] = Sqrt(Sum(E[n, i] * E[n, i])) / I the average euclidean distance of vector element of a given sample <br> Dr[n] = Sqrt(Sum(Er[n, i] * Er[n, i])) / I the average relative euclidean distance of vector element of a given sample <br> n in N set, N number of samples <br> i in I set, I number of elements in input vector resticted to elements with modulus grater then 'IgnoreIf' soil <br> &quot;Activation&quot; Sum of activation (gaussian function) of all neuron <br></td>
</tr>
<tr class="list2">
<td class="itemname"><a class="bold"  href="eANNUtil.html">eANNUtil</a></td>
<td class="itemdesc">&nbsp;</td>
</tr>
</table>
<hr noshade size="1"><span class="appinfo"><em>Generated by <a  target="_parent" href="http://pasdoc.sourceforge.net/">PasDoc 0.11.0</a> on 2008-09-28 23:03:41</em>
</span>
</body></html>
